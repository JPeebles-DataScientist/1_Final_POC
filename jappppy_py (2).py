# -*- coding: utf-8 -*-
"""Jappppy.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vd40Jeic9ij3Qe-Q4jbzxPyUrqkH7d-5
"""

import streamlit as st
import pandas as pd
import geopandas as gpd # Import GeoPandas
from shapely.geometry import Point # To create Point geometries
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import plotly.express as px
import io

# --- Streamlit Page Configuration ---
st.set_page_config(layout="wide", page_title="HCP Geospatial Segmentation")

st.title("Interactive HCP Geospatial Segmentation Tool (with GeoPandas)")
st.markdown("""
This tool segments Healthcare Providers (HCPs) based on transaction count and projected geographic location using K-Means clustering.
This version uses GeoPandas for more accurate spatial processing.

**Instructions:**
1.  Upload a CSV file with columns: `hcp_id`, `trx_count`, `latitude`, `longitude`.
    *   *(Optional but Recommended):* Include `state`, `city`, `zip_code` for better geographic validation.
2.  Select the desired number of clusters (segments).
3.  Click 'Run Segmentation'.
4.  Review the interactive map, geographic cluster summary, and results table.
5.  Download the segmented data.
""")

# --- File Upload ---
uploaded_file = st.file_uploader("1. Upload your HCP Data (CSV)", type="csv")

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("File Uploaded Successfully!")

        # --- Data Validation ---
        required_columns = ['hcp_id', 'trx_count', 'latitude', 'longitude']
        optional_geo_columns = ['state', 'city', 'zip_code']
        present_optional_geo = [col for col in optional_geo_columns if col in df.columns]

        if not all(col in df.columns for col in required_columns):
            st.error(f"Error: CSV must contain the core columns: {', '.join(required_columns)}")
            st.stop()

        try:
            df['trx_count'] = pd.to_numeric(df['trx_count'])
            df['latitude'] = pd.to_numeric(df['latitude'])
            df['longitude'] = pd.to_numeric(df['longitude'])
        except ValueError as e:
            st.error(f"Error converting data to numeric types. Please check columns 'trx_count', 'latitude', 'longitude'. Details: {e}")
            st.stop()

        st.write("### Input Data Preview (First 5 Rows)")
        st.dataframe(df.head())

        # --- Handle Missing Values in core columns ---
        initial_rows = len(df)
        df_cleaned = df.dropna(subset=['trx_count', 'latitude', 'longitude']).copy()
        rows_dropped = initial_rows - len(df_cleaned)
        if rows_dropped > 0:
            st.warning(f"Warning: Dropped {rows_dropped} rows due to missing values in core clustering columns.")

        if len(df_cleaned) < 2:
             st.error("Error: Not enough valid data remaining after handling missing values (minimum 2 required).")
             st.stop()

        # --- Convert to GeoDataFrame and Project ---
        st.write("DEBUG: Converting to GeoDataFrame and projecting coordinates...")
        try:
            # Create geometry from lat/lon
            geometry = [Point(xy) for xy in zip(df_cleaned['longitude'], df_cleaned['latitude'])]
            gdf = gpd.GeoDataFrame(df_cleaned, geometry=geometry, crs="EPSG:4326") # Assume WGS84 for input lat/lon

            # Project to a suitable CRS for contiguous US (Albers Equal Area Conic)
            # EPSG:5070 is a common choice for NAD83 / Conus Albers
            gdf_projected = gdf.to_crs("EPSG:5070") #
            st.write(f"DEBUG: Data projected to EPSG:5070. Projected GDF head:")
            # For debugging, show a snippet of projected coordinates
            # gdf_projected['proj_x'] = gdf_projected.geometry.x
            # gdf_projected['proj_y'] = gdf_projected.geometry.y
            # st.dataframe(gdf_projected[['hcp_id', 'proj_x', 'proj_y']].head())

        except Exception as e_geopandas:
            st.error(f"Error during GeoPandas processing (projection): {e_geopandas}")
            st.stop()


        # --- User Input for Number of Clusters ---
        st.markdown("---")
        max_k = max(2, len(gdf_projected))
        default_k = min(5, max_k)
        k_clusters = st.slider("2. Select the number of clusters (k):", min_value=2, max_value=min(50, max_k), value=default_k, step=1)

        # --- Clustering Execution ---
        st.markdown("---")
        if st.button(f"3. Run Segmentation for {k_clusters} Clusters", type="primary"):
            with st.spinner('Performing clustering... Please wait.'):
                # --- Feature Selection for Clustering (using projected coordinates) ---
                # Extract projected X and Y coordinates
                gdf_projected['proj_x'] = gdf_projected.geometry.x
                gdf_projected['proj_y'] = gdf_projected.geometry.y

                features_for_clustering = ['proj_x', 'proj_y', 'trx_count']
                X = gdf_projected[features_for_clustering]

                # --- Scale features ---
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                st.write("DEBUG: Features (projected X, Y, trx_count) scaled.")

                # --- KMeans Clustering ---
                kmeans = KMeans(n_clusters=k_clusters, init='k-means++', random_state=42, n_init=10) #
                kmeans.fit(X_scaled)

                # Assign cluster labels back to the original GeoDataFrame (gdf, which has original lat/lon)
                # We use the index to align as gdf_projected might have a different order if rows were dropped
                gdf.loc[gdf_projected.index, 'cluster'] = kmeans.labels_
                # Also add to df_cleaned for consistency if optional columns are used from it later
                df_cleaned.loc[gdf_projected.index, 'cluster'] = kmeans.labels_


            st.success(f"Segmentation Complete! {k_clusters} clusters generated.")
            st.markdown("---")

            # --- Display Results ---
            st.write("### 4. Segmentation Results")

            # --- Map Visualization using Plotly Express (using original lat/lon from gdf) ---
            st.write("#### Interactive Map")
            st.markdown("HCP locations colored by assigned cluster. Hover for details.")
            try:
                gdf['cluster'] = gdf['cluster'].astype(str)

                hover_data_dict = {"latitude": False, "longitude": False, "cluster": True, "trx_count": True}
                for col in present_optional_geo:
                    if col in gdf.columns: # Ensure optional columns are in gdf
                         hover_data_dict[col] = True

                fig = px.scatter_mapbox(gdf,
                                        lat="latitude",
                                        lon="longitude",
                                        color="cluster",
                                        size="trx_count",
                                        hover_name="hcp_id",
                                        hover_data=hover_data_dict,
                                        color_discrete_sequence=px.colors.qualitative.Vivid,
                                        zoom=3.5,
                                        height=600,
                                        mapbox_style="carto-positron")

                fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
                st.plotly_chart(fig, use_container_width=True)
            except Exception as map_error:
                st.error(f"Error creating map: {map_error}")

            st.markdown("---")

            # --- Geographic Cluster Summary ---
            if present_optional_geo:
                st.write("#### Geographic Cluster Summary")
                st.markdown(f"Count of HCPs per Cluster and {', '.join(present_optional_geo)}.")
                grouping_fields = ['cluster'] + [col for col in present_optional_geo if col in df_cleaned.columns]
                if len(grouping_fields) > 1: # Ensure there's something to group by besides cluster
                    geo_summary = df_cleaned.groupby(grouping_fields).size().reset_index(name='HCP Count')
                    st.dataframe(geo_summary.sort_values(by=['cluster'] + [col for col in present_optional_geo if col in df_cleaned.columns]))
                else:
                    st.write("Optional geographic columns not found in data for summary.")
                st.markdown("*(Use this table to check if clusters generally fall within consistent geographic areas)*")
                st.markdown("---")

            # --- Results Table ---
            st.write("#### Full Segmented Data Table")
            st.markdown("Table showing HCPs with their assigned cluster ID.")
            display_columns = ['hcp_id', 'trx_count', 'latitude', 'longitude'] + \
                              [col for col in present_optional_geo if col in gdf.columns] + \
                              ['cluster']
            # Ensure all display_columns actually exist in gdf before trying to select them
            final_display_columns = [col for col in display_columns if col in gdf.columns]
            st.dataframe(gdf[final_display_columns].sort_values('cluster'))

            # --- Download Button ---
            st.markdown("---")
            st.write("### 5. Export Results")
            try:
                output = io.BytesIO()
                df_to_save = gdf[final_display_columns]
                df_to_save.to_csv(output, index=False, encoding='utf-8')
                output.seek(0)

                st.download_button(label="Download Segmented Data as CSV",
                                   data=output,
                                   file_name=f'hcp_segmented_data_{k_clusters}_clusters.csv',
                                   mime='text/csv',
                                   key='download-csv')
            except Exception as download_error:
                st.error(f"Error preparing download link: {download_error}")

    except pd.errors.EmptyDataError:
        st.error("Error: The uploaded CSV file appears to be empty.")
    except ImportError:
        st.error("GeoPandas or one of its dependencies is not installed correctly. Please check your environment.")
    except Exception as e:
        st.error(f"An unexpected error occurred: {e}")
        st.error("Please ensure the uploaded file is valid and all dependencies are installed.")
        # import traceback
        # st.code(traceback.format_exc()) # Uncomment for detailed traceback

else:
    st.info("Awaiting CSV file upload to begin.")