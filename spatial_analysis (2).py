# -*- coding: utf-8 -*-
"""spatial_analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HbQ8EUOsC3w8KBlzCS7hhHYndfWqQbS8
"""

import streamlit as st
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from sklearn.preprocessing import StandardScaler
import plotly.express as px
import io

# PySAL and spopt imports
import libpysal
from spopt.region import WardSpatial
import traceback # For more detailed error messages

# --- Streamlit Page Configuration ---
st.set_page_config(layout="wide", page_title="HCP Geographic Regionalization (WardSpatial)")

st.title("HCP Geographic Regionalization Tool (Location-Focused WardSpatial)")
st.markdown("""
This tool uses the **WardSpatial algorithm** to create geographically coherent national regions.
It **prioritizes geographic location (projected X, Y coordinates)** for forming these broad regions.
Transaction count (`trx_count`) is then a characteristic of these regions, used for map visualization.

**Instructions:**
1.  Upload a CSV file with columns: `hcp_id`, `trx_count`, `latitude`, `longitude`.
    *   *(Highly Recommended):* Include `state`, `city`, `zip_code` for validation and region naming.
2.  Select the desired number of **broad national regions**.
3.  Adjust the **Number of Neighbors (KNN)** for connectivity (use a very small value like 2-4 for national data).
4.  Click 'Run Regionalization'.
""")

# --- File Upload ---
uploaded_file = st.file_uploader("1. Upload your HCP Data (CSV)", type="csv")

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("File Uploaded Successfully!")

        # --- Data Validation ---
        required_columns = ['hcp_id', 'trx_count', 'latitude', 'longitude']
        optional_geo_columns = ['state', 'city', 'zip_code'] # Ensure these are lowercase if your CSV has them

        # Convert uploaded df column names to lowercase for consistency
        df.columns = [col.lower().replace(' ', '_') for col in df.columns]

        present_optional_geo = [col for col in optional_geo_columns if col in df.columns]

        if not all(col in df.columns for col in required_columns):
            st.error(f"Error: CSV must contain the core columns: {', '.join(required_columns)} (case-insensitive check performed). Found: {list(df.columns)}")
            st.stop()

        try:
            df['trx_count'] = pd.to_numeric(df['trx_count'])
            df['latitude'] = pd.to_numeric(df['latitude'])
            df['longitude'] = pd.to_numeric(df['longitude'])
        except ValueError as e:
            st.error(f"Error converting data to numeric types. Please check columns 'trx_count', 'latitude', 'longitude'. Details: {e}")
            st.stop()

        st.write("### Input Data Preview (First 5 Rows)")
        st.dataframe(df.head())

        initial_rows = len(df)
        df_cleaned = df.dropna(subset=['trx_count', 'latitude', 'longitude']).copy()
        rows_dropped = initial_rows - len(df_cleaned)
        if rows_dropped > 0:
            st.warning(f"Warning: Dropped {rows_dropped} rows due to missing values in core columns.")

        if len(df_cleaned) < 5: # WardSpatial needs a few points
             st.error("Error: Not enough valid data (minimum ~5 recommended for this algorithm).")
             st.stop()

        # --- Convert to GeoDataFrame and Project ---
        st.write("DEBUG: Converting to GeoDataFrame and projecting coordinates...")
        geometry = [Point(xy) for xy in zip(df_cleaned['longitude'], df_cleaned['latitude'])]

        # This GDF will hold ALL original columns (including optional ones) + original geometry
        # It will be used for the final output after region_id is assigned.
        gdf_original_all_cols = gpd.GeoDataFrame(df_cleaned.copy(), geometry=geometry, crs="EPSG:4326")

        # Create a GDF specifically for projection and model input (only essential columns)
        # This ensures that only relevant data is processed by GeoPandas for projection.
        gdf_for_projection = gpd.GeoDataFrame(
            df_cleaned[['hcp_id', 'trx_count', 'latitude', 'longitude']].copy(), # Keep trx_count for map sizing
            geometry=geometry,
            crs="EPSG:4326"
        )
        # EPSG:5070 is NAD83 / Conus Albers - good for contiguous US
        gdf_projected = gdf_for_projection.to_crs("EPSG:5070")
        st.write(f"DEBUG: Data projected to EPSG:5070.")

        gdf_projected['proj_x'] = gdf_projected.geometry.x
        gdf_projected['proj_y'] = gdf_projected.geometry.y

        # --- User Input for WardSpatial Parameters ---
        st.sidebar.header("Regionalization Parameters")
        n_regions = st.sidebar.slider("2. Number of National Regions:",
                                          min_value=2,
                                          max_value=min(10, len(gdf_projected)//3 if len(gdf_projected)//3 >=2 else 2),
                                          value=min(3, len(gdf_projected)//3 if len(gdf_projected)//3 >=2 else 2),
                                          step=1,
                                          help="Select the number of broad geographic regions (e.g., West, Central, East).")

        max_k_neighbors = len(gdf_projected) - 1
        if max_k_neighbors < 1:
            st.error("Not enough unique data points to define neighbors.")
            st.stop()

        k_neighbors_val = st.sidebar.slider("Number of Neighbors (KNN for connectivity):",
                                        min_value=2,
                                        max_value=min(5, max_k_neighbors),
                                        value=min(3, max_k_neighbors),
                                        step=1,
                                        help="CRITICAL: Use a very small value (e.g., 2-3) for national data to ensure local connections only.")


        # --- WardSpatial Execution ---
        st.markdown("---")
        if st.button(f"3. Run Geographic Regionalization for {n_regions} Regions", type="primary"):
            with st.spinner(f'Building KNN (k={k_neighbors_val}) graph and running WardSpatial... This may take a moment.'):

                attributes_to_cluster_on = ['proj_x', 'proj_y']
                data_for_coord_scaling = gdf_projected[attributes_to_cluster_on].copy()

                coord_scaler = StandardScaler()
                scaled_coordinates = coord_scaler.fit_transform(data_for_coord_scaling)

                # gdf_for_model will be gdf_projected with added scaled coordinate columns
                gdf_for_model = gdf_projected.copy()
                gdf_for_model['scaled_proj_x'] = scaled_coordinates[:, 0]
                gdf_for_model['scaled_proj_y'] = scaled_coordinates[:, 1]

                attribute_names_for_model = ['scaled_proj_x', 'scaled_proj_y']
                st.write(f"DEBUG: Attributes for WardSpatial (scaled geographic coordinates only): {attribute_names_for_model}")

                st.write(f"DEBUG: Building KNN weights matrix with k={k_neighbors_val}...")
                try:
                    # Ensure active geometry is set for libpysal
                    gdf_projected_for_weights = gdf_projected.set_geometry('geometry')
                    knn_weights = libpysal.weights.KNN.from_dataframe(gdf_projected_for_weights, k=k_neighbors_val)
                    st.write("DEBUG: KNN weights matrix built.")
                except Exception as e_weights:
                    st.error(f"Error building spatial weights: {e_weights}")
                    st.code(traceback.format_exc())
                    st.stop()

                st.write("DEBUG: Running WardSpatial algorithm...")
                try:
                    model_ward = WardSpatial(
                        gdf_for_model,
                        w=knn_weights,
                        attrs_name=attribute_names_for_model,
                        n_clusters=n_regions
                    )
                    model_ward.solve()
                    st.write("DEBUG: WardSpatial solved.")
                except Exception as e_ward:
                    st.error(f"Error during WardSpatial execution: {e_ward}")
                    st.code(traceback.format_exc())
                    st.stop()

                # Assign cluster labels back to the GeoDataFrame that has ALL original columns + original geometry
                # model_ward.labels_ corresponds to the order in gdf_for_model (which has same index as gdf_projected)
                # gdf_original_all_cols has the same index as df_cleaned -> gdf_for_projection -> gdf_projected -> gdf_for_model
                gdf_original_all_cols.loc[gdf_for_model.index, 'region_id'] = model_ward.labels_

                # --- DEBUG: Print head of GDF with assigned region_id ---
                st.write("DEBUG: Head of data with assigned region_id (before map/table):")
                debug_cols_list = ['hcp_id', 'trx_count', 'latitude', 'longitude', 'region_id'] + \
                                  [col for col in present_optional_geo if col in gdf_original_all_cols.columns]
                # Ensure all debug_cols_list are actually in gdf_original_all_cols
                final_debug_cols = [col for col in debug_cols_list if col in gdf_original_all_cols.columns]
                st.dataframe(gdf_original_all_cols[final_debug_cols].head(20)) # Show more rows for debugging
                # --- End DEBUG ---

            st.success(f"Geographic Regionalization Complete! {n_regions} regions generated.")
            st.markdown("---")

            # --- Display Results (using gdf_original_all_cols) ---
            st.write("### 4. Regionalization Results")

            if 'region_id' not in gdf_original_all_cols.columns:
                st.error("CRITICAL DEBUG: 'region_id' column not found in gdf_original_all_cols before plotting!")
                st.stop()
            gdf_original_all_cols['region_id'] = gdf_original_all_cols['region_id'].astype(str)


            # --- Map Visualization ---
            st.write("#### Interactive Map of Geographic Regions")
            st.markdown("HCP locations colored by assigned region. Hover for details.")
            try:
                hover_data_dict = {"latitude": False, "longitude": False, "region_id": True, "trx_count": True}
                for col_name in present_optional_geo: # Use col_name to avoid conflict
                    if col_name in gdf_original_all_cols.columns: hover_data_dict[col_name] = True

                fig = px.scatter_mapbox(gdf_original_all_cols.dropna(subset=['region_id']),
                                        lat="latitude",
                                        lon="longitude",
                                        color="region_id",
                                        size="trx_count",
                                        hover_name="hcp_id",
                                        hover_data=hover_data_dict,
                                        color_discrete_sequence=px.colors.qualitative.Set1,
                                        zoom=3.0,
                                        height=600,
                                        mapbox_style="carto-positron")
                fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
                st.plotly_chart(fig, use_container_width=True)
            except Exception as map_error:
                st.error(f"Error creating map: {map_error}")
                st.code(traceback.format_exc())


            # --- Geographic Region Summary ---
            if present_optional_geo:
                st.write("#### Geographic Region Summary")
                st.markdown(f"Count of HCPs per Region and {', '.join(present_optional_geo)}.")
                grouping_fields_list = ['region_id'] + [col_name for col_name in present_optional_geo if col_name in gdf_original_all_cols.columns]

                # Ensure all grouping_fields_list are actually in gdf_original_all_cols
                final_grouping_fields = [col for col in grouping_fields_list if col in gdf_original_all_cols.columns]

                if len(final_grouping_fields) > 1 and 'region_id' in gdf_original_all_cols.columns:
                    geo_summary_df = gdf_original_all_cols.dropna(subset=['region_id'])
                    geo_summary = geo_summary_df.groupby(final_grouping_fields).size().reset_index(name='HCP Count')
                    st.dataframe(geo_summary.sort_values(by=final_grouping_fields))
                else:
                    st.write("Optional geographic columns or region assignments not found for summary, or only region_id available.")
                st.markdown("*(Use this table to check if regions are geographically consistent)*")
                st.markdown("---")

            # --- Results Table ---
            st.write("#### Full Segmented Data Table")
            display_columns_final_list = ['hcp_id', 'trx_count', 'latitude', 'longitude'] + \
                                         [col_name for col_name in present_optional_geo if col_name in gdf_original_all_cols.columns] + \
                                         ['region_id']
            final_display_columns_present = [col for col in display_columns_final_list if col in gdf_original_all_cols.columns]

            if 'region_id' in gdf_original_all_cols.columns:
                st.dataframe(gdf_original_all_cols[final_display_columns_present].sort_values('region_id'))
            else:
                st.write("Region information not available for the table.")


            # --- Download Button ---
            st.markdown("---")
            st.write("### 5. Export Results")
            try:
                output = io.BytesIO()
                if 'region_id' in gdf_original_all_cols.columns:
                    df_to_save = gdf_original_all_cols[final_display_columns_present]
                    df_to_save.to_csv(output, index=False, encoding='utf-8')
                    output.seek(0)
                    st.download_button(label="Download Regionalized Data as CSV",
                                   data=output,
                                   file_name=f'hcp_geographic_regions_{n_regions}.csv',
                                   mime='text/csv',
                                   key='download-ward-geo-regions-csv')
                else:
                    st.write("No regionalized data to download.")
            except Exception as download_error:
                st.error(f"Error preparing download link: {download_error}")
                st.code(traceback.format_exc())


    except pd.errors.EmptyDataError:
        st.error("Error: The uploaded CSV file appears to be empty.")
    except ImportError as e_import:
        st.error(f"ImportError: A required library (likely PySAL, spopt, or a dependency) is not installed. Details: {e_import}")
        st.error("Please ensure your environment has all libraries from requirements.txt installed, especially GeoPandas and PySAL components.")
        st.code(traceback.format_exc())
    except Exception as e:
        st.error(f"An unexpected error occurred: {e}")
        st.error("Please ensure the uploaded file is valid and all dependencies are installed.")
        st.code(traceback.format_exc())

else:
    st.info("Awaiting CSV file upload to begin.")