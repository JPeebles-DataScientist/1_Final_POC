# -*- coding: utf-8 -*-
"""Jappppy.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vd40Jeic9ij3Qe-Q4jbzxPyUrqkH7d-5
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import plotly.express as px
import io

# --- Streamlit Page Configuration ---
st.set_page_config(layout="wide", page_title="HCP Geospatial Segmentation")

st.title("Interactive HCP Geospatial Segmentation Tool")
st.markdown("""
This tool segments Healthcare Providers (HCPs) based on transaction count and location using K-Means clustering.

**Instructions:**
1.  Upload a CSV file with columns: `hcp_id`, `trx_count`, `latitude`, `longitude`.
    *   *(Optional but Recommended):* Include `state`, `city`, `zip_code` for better geographic validation.
2.  Select the desired number of clusters (segments).
3.  Click 'Run Segmentation'.
4.  Review the interactive map, geographic cluster summary, and results table.
5.  Download the segmented data.
""")

# --- File Upload ---
uploaded_file = st.file_uploader("1. Upload your HCP Data (CSV)", type="csv")

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("File Uploaded Successfully!")

        # --- Data Validation ---
        required_columns = ['hcp_id', 'trx_count', 'latitude', 'longitude']
        optional_geo_columns = ['state', 'city', 'zip_code'] # Check for these optional columns
        present_optional_geo = [col for col in optional_geo_columns if col in df.columns]

        if not all(col in df.columns for col in required_columns):
            st.error(f"Error: CSV must contain the core columns: {', '.join(required_columns)}")
            st.stop()

        # Ensure correct data types for core columns
        try:
            df['trx_count'] = pd.to_numeric(df['trx_count'])
            df['latitude'] = pd.to_numeric(df['latitude'])
            df['longitude'] = pd.to_numeric(df['longitude'])
        except ValueError as e:
            st.error(f"Error converting data to numeric types. Please check columns 'trx_count', 'latitude', 'longitude'. Details: {e}")
            st.stop()

        st.write("### Input Data Preview (First 5 Rows)")
        st.dataframe(df.head())

        # --- Handle Missing Values ---
        initial_rows = len(df)
        # Also check for missing values in present optional geo columns if needed for clustering (not needed here)
        df_cleaned = df.dropna(subset=['trx_count', 'latitude', 'longitude']).copy()
        rows_dropped = initial_rows - len(df_cleaned)
        if rows_dropped > 0:
            st.warning(f"Warning: Dropped {rows_dropped} rows due to missing values in core clustering columns.")

        if len(df_cleaned) < 2: # Need at least 2 points to cluster
             st.error("Error: Not enough valid data remaining after handling missing values (minimum 2 required).")
             st.stop()

        # --- User Input for Number of Clusters ---
        st.markdown("---")
        max_k = max(2, len(df_cleaned))
        default_k = min(5, max_k)
        k = st.slider("2. Select the number of clusters (k):", min_value=2, max_value=min(50, max_k), value=default_k, step=1)

        # --- Clustering Execution ---
        st.markdown("---")
        if st.button(f"3. Run Segmentation for {k} Clusters", type="primary"):
            with st.spinner('Performing clustering... Please wait.'):
                # --- Feature Selection and Scaling ---
                # Cluster ONLY on trx_count and location
                features_for_clustering = ['trx_count', 'latitude', 'longitude']
                X = df_cleaned[features_for_clustering]

                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)

                # --- KMeans Clustering ---
                kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10)
                kmeans.fit(X_scaled)

                # Assign cluster labels back to the cleaned dataframe
                df_cleaned.loc[:, 'cluster'] = kmeans.labels_

            st.success(f"Segmentation Complete! {k} clusters generated.")
            st.markdown("---")

            # --- Display Results ---
            st.write("### 4. Segmentation Results")

            # --- Map Visualization using Plotly Express ---
            st.write("#### Interactive Map")
            st.markdown("HCP locations colored by assigned cluster. Hover for details (including State/City/Zip if provided).")
            try:
                df_cleaned['cluster'] = df_cleaned['cluster'].astype(str) # Treat cluster as categorical for color

                # Build hover data dynamically based on available columns
                hover_data_dict = {"latitude": False, "longitude": False, "cluster": True, "trx_count": True}
                for col in present_optional_geo:
                    hover_data_dict[col] = True # Add optional geo columns to hover

                fig = px.scatter_mapbox(df_cleaned,
                                        lat="latitude",
                                        lon="longitude",
                                        color="cluster",
                                        size="trx_count",
                                        hover_name="hcp_id",
                                        hover_data=hover_data_dict,
                                        color_discrete_sequence=px.colors.qualitative.Vivid, # Use a vivid color scheme
                                        zoom=3.5,
                                        height=600,
                                        mapbox_style="carto-positron")

                fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
                st.plotly_chart(fig, use_container_width=True)
            except Exception as map_error:
                st.error(f"Error creating map: {map_error}")

            st.markdown("---")

            # --- Geographic Cluster Summary (NEW SECTION) ---
            if present_optional_geo: # Only show if optional geo columns exist
                st.write("#### Geographic Cluster Summary")
                st.markdown(f"Count of HCPs per Cluster and {', '.join(present_optional_geo)}.")

                # Create summary grouped by cluster and available geo fields
                grouping_fields = ['cluster'] + present_optional_geo
                geo_summary = df_cleaned.groupby(grouping_fields).size().reset_index(name='HCP Count')

                # Display the summary table
                st.dataframe(geo_summary.sort_values(by=['cluster'] + present_optional_geo))
                st.markdown("*(Use this table to check if clusters generally fall within consistent geographic areas)*")
                st.markdown("---")


            # --- Results Table ---
            st.write("#### Full Segmented Data Table")
            st.markdown("Table showing HCPs with their assigned cluster ID (and State/City/Zip if provided).")

            # Include optional geo columns in the output table if they exist
            display_columns = ['hcp_id', 'trx_count', 'latitude', 'longitude'] + present_optional_geo + ['cluster']
            st.dataframe(df_cleaned[display_columns].sort_values('cluster'))


            # --- Download Button ---
            st.markdown("---")
            st.write("### 5. Export Results")
            try:
                output = io.BytesIO()
                # Include optional geo columns in the download file if they exist
                df_to_save = df_cleaned[display_columns]
                df_to_save.to_csv(output, index=False, encoding='utf-8')
                output.seek(0)

                st.download_button(label="Download Segmented Data as CSV",
                                   data=output,
                                   file_name=f'hcp_segmented_data_{k}_clusters.csv',
                                   mime='text/csv',
                                   key='download-csv')
            except Exception as download_error:
                st.error(f"Error preparing download link: {download_error}")


    except pd.errors.EmptyDataError:
        st.error("Error: The uploaded CSV file appears to be empty.")
    except Exception as e:
        st.error(f"An unexpected error occurred during processing: {e}")
        st.error("Please ensure the uploaded file is a valid CSV and has the correct format/columns.")

else:
    st.info("Awaiting CSV file upload to begin.")